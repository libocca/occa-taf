# 2022-04-20

## Meeting Link

[Join the MS Teams meeting](https://teams.microsoft.com/l/meetup-join/19%3ameeting_NDBhZmQyMTUtMzEzMy00ZWJkLTkzZDAtMzRiZDg1YWU5OTQ3%40thread.v2/0?context=%7b%22Tid%22%3a%220cfca185-25f7-49e3-8ae7-704d5326e285%22%2c%22Oid%22%3a%22e76e8444-bf17-4212-b407-066369e3264c%22%7d)

## Attendees

- 

## Follow-up
*Action items from last meeting*

- [x] Document [compiler support for C++17](https://en.cppreference.com/w/cpp/compiler_support#cpp17)
- [ ] Find volunteers to lead the efforts in various aspects of user documentation

## Agenda

1. Kernel caching
   - OpenCL, SYCL/DPC++ hashing
   - Kernel/device compatibility
   - Multiple caches (e.g. common + specific)
2. MPI aware jitting

## Notes

### Kernel Caching

#### OpenCL, SYCL/DPC++ Hashing

- Currently this is based on the device and platform id
  - See [issue 442](https://github.com/libocca/occa/issues/422)
  - Even for the same OpenCL implementation, there is no guarantee that the platform id will be consistent across compute nodes
- It is more sensible to check if a device is compatible with a compiled kernels, e.g.
  - Is the same device type, vendor
  - Supports the OpenCL spec used during jitting

#### Device/Kernel Compatibility

- Kernel hashes are a unique kernel identifier and provided a short-cut to finding cached kernels
- However, we should also consider more detailed checks, e.g. against compiler flags.
- This should be standardized across all backends, to avoid differences that exist now (e.g., OpenCL)

#### Multiple Caches

Possible approaches (these are not mutually exclusive):
1. Pass a cache-directory argument via the `occa::json` for kernel properties
   - Pro: easy to implement
   - Con: This would need to override the `OCCA_CACHE_DIR` env variable, which is opposite to how most env variables work 
2. Change `OCCA_CACHE_DIR` to `OCCA_CACHE_DIRS`&mdash;a (colon) separated list of directories
   - Pro: few/no changes needed to application code
   - Con: increased time to find/load kernels
3. Introduce separate `OCCA_SYSTEM_CACHE_DIR` env variable
   - Really a variation of the second option 

### MPI aware jitting

- Very little MPI code exists, and currently adds little value
- Ideally, MPI dependency can be removed altogether
  - Requires a mechanism for dependency injection 
  - Q: What about C/Fortran applications?
- Alternatively, an interface explicitly for kernel builds with MPI 
  - An MPI option already exists in the build systems
  - Easy to create wrappers for C, Fortran

#### Proposal 1

```
void occa::compileKernels(
  std::vector<std::string> kernel_files,
  std::vector<std::string> kernel_names,
  std::function<void(size_t kernel_number)> kernel_builder
);

std::vector<occa::kernels> occa::loadKernels(
  std::vector<std::string> kernel_files,
  std::vector<std::string> kernel_names,
  std::function<occa::kernel(size_t kernel_number)> kernel_loader
);
```

Example Usage

```
int rank,number_of_ranks;
MPI_Comm_size(MPI_COMM_WORLD,&number_of_ranks);
MPI_Comm_rank(MPI_COMM_WORLD,&rank);

occa::device d;

std::vector<std::string> files = {"file1.okl","file2.okl","file3.okl"};
std::vector<std::string> kernel_names = {"kernel1","kernel2","kernel3"};

occa::json kernel_properties;
kernel_properties["defines/BLOCK_SIZE"] = 1024;

occa::compileKernels(files,kernel_names,
  [&](size_t kernel_number) {
    //Round-robin compilation using MPI ranks
    if((rank < kernels.size()) && (rank == kernel_number%number_of_ranks)) {
      device.buildKernel(files[kernel_number],
                         kernels[kernel_number],
                         kernel_properties);
    }
  });

auto kernels = occa::loadKernels(files,kernel_names,
  [&](size_t kernel_number) {
    return device.buildKernel(files[kernel_number],
                         kernels[kernel_number],
                         kernel_properties);
  });

```

#### Proposal 2

```
// Compile on root; load on all ranks
occa::kernel occa::buildKernel(
  occa::device& d,
  std::string file_name,
  std::string kernel_name,
  int root,
  MPI_Comm comm,
  occa::json kernel_properties = {}
);


// Round-robin compile kernels on all ranks
void occa::compileKernels(
  occa::device& d,
  std::vector<std::string> files,
  std::vector<str::string> kernel_names,
  MPI_Comm comm,
  occa::json kernel_properties = {}
);

// Load kernels on all ranks
std::vector<occa::kernels> occa::loadKernels(
  occa::device& d,
  std::vector<std::string> files,
  std::vector<str::string> kernel_names,
  MPI_Comm comm,
  occa::json kernel_properties = {}
);
```

Example Usage
```
int rank,number_of_ranks;
MPI_Comm_size(MPI_COMM_WORLD,&number_of_ranks);
MPI_Comm_rank(MPI_COMM_WORLD,&rank);

occa::device d;

std::vector<std::string> files = {"file1.okl","file2.okl","file3.okl"};
std::vector<std::string> kernel_names = {"kernel1","kernel2","kernel3"};

occa::json kernel_properties;
kernel_properties["defines/BLOCK_SIZE"] = 1024;

MPI_Comm new_comm;
int key = rank;
int color = (rank < 4) ? 0 : 1;
MPI_Comm_split(MPI_COMM_WORLD,color,key,&new_comm);

// The first four ranks compile
if(0==color) {
  occa::compileKernels(d,files,kernel_names,new_comm,kernel_properties);
}

// Everone else do something useful in the meantime ...

MPI_Barrier(MPI_COMM_WORLD);
// All ranks load all the kernels
auto kernels = occa::loadKernels(d,files,kernel_names,MPI_COMM_WORLD,kernel_properties);
```

## Action Items

- [ ]

## Next Meeting

- [2022-05-04](2022-05-04.md)