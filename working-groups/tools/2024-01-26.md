# 2024-01-26

## Meeting Link

https://teams.microsoft.com/l/meetup-join/19%3ameeting_NmY3YmViNDctYTFmOC00N2E2LWEzODktNDU5MjBmOGFjZTM0%40thread.v2/0?context=%7b%22Tid%22%3a%223dd8961f-e488-4e60-8e11-a82d994e183d%22%2c%22Oid%22%3a%22283778cd-dac5-4948-96b5-f82885ad5d24%22%7d

## Follow-up

N/A

## Agenda

1. Discuss OCCA callback interface

## Notes

- There are important OCCA events: memory allocation, kernel launch, jit, etc
- OCCA provides a callback interface (list of function pointers)
- THAPI can call regsiter_occa_callback and provide a function implementation
- OCCA calls the callback when an important event happnes
- OCCA provide register_occa_callback
- THAPI provides the function pointer, and this is passed as an arg to
  register_occa_callback
- OCCA also needs to provide a list of events in a struct
  - data motion, jitting, kernel launches, whatever
- then, for example, in memory::copyFrom, occa calls the registered callback
  for the data_motion event
- Since THAPI provided the callback, thapi's code executes here
- What are the requirements on the callback implementations provided to OCCA?
  - blocking, nonblocking?
  - timing?
- I don't know how to reason about the overhead here
- OpenMP example here; https://git.rwth-aachen.de/OpenMPTools/OMPT-Examples/-/blob/master/example5/sample.cc?ref_type=heads
- Important events:
  - device_setup
    - begin and end
  - device malloc
  - stream (begin and end?)
  - memory copies (To and From)
  - occa_kernel_run
    - maybe also start and finish events?
  - occa_kernel_build
    - async compilation?
    - parallel builds :)
- two details:
  - tracing stuff at the occa layer
  - intercepting device apis (cuda, hip, etc) which thapi already does
- what additional context can be provided to callbacks?
  - memory allocation size?
  - kernel name of launched kernel?
  - others?

## Action Items

- [x] Set up the next meeting
- [ ] Discuss callback implementation details

## Next Meeting

- 2024-02-09
